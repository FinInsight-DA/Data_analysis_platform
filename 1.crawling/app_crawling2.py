"""
Insightpage API í¬ë¡¤ë§ Streamlit ì•±
"""

import streamlit as st
import pandas as pd
from datetime import datetime, timedelta
from crawling import InsightPageAPI
#from insightpage_api import InsightPageAPI

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="í¬ë¡¤ë§ í˜ì´ì§€",
    page_icon="ğŸ“Š",
    layout="wide"
)

# CSS ìŠ¤íƒ€ì¼
st.markdown("""
<style>
    .main-header {
        font-size: 2rem;
        font-weight: bold;
        margin-bottom: 2rem;
    }
    .stButton>button {
        width: 100%;
        background-color: #ff4b4b;
        color: white;
        font-weight: bold;
        padding: 0.5rem 1rem;
        border-radius: 0.5rem;
    }
</style>
""", unsafe_allow_html=True)


def main():
    # -----------------
    # ì‚¬ì´ë“œë°” ì¶”ê°€ (ë‚˜ì¤‘ì— ë‹¤ë¥¸ ê¸°ëŠ¥/ë¡œê·¸/KPI ë“±ì„ ë„£ì„ ì˜ˆì •)
    # -----------------
    with st.sidebar:
        st.markdown("### ğŸ› ï¸ ì‚¬ì´ë“œë°”")
        st.info("ì´ ì˜ì—­ì€ í–¥í›„ ì¶”ê°€ ì˜ˆì •.")
        st.markdown("---")
        st.caption(f"ì•± ë²„ì „: 1.0.0")


    st.markdown('<div class="main-header">í¬ë¡¤ë§ í˜ì´ì§€</div>', unsafe_allow_html=True)
    
    # íƒ­ ìƒì„±
    tab1, tab2 = st.tabs(["í¬ë¡¤ë§API", "í•™ìŠµë°ì´í„°"])
    
    # -----------------
    # íƒ­ 1: í¬ë¡¤ë§API
    # -----------------
    with tab1:
        st.markdown("### í¬ë¡¤ë§API (ì„¤ì •ì„¸ì…˜)")
        
        # API ì„¤ì •
        api_key = st.text_input(
            "API í‚¤",
            # ì•ˆì „ì„ ìœ„í•´ ì‹¤ì œ í‚¤ ëŒ€ì‹  placeholder ì‚¬ìš© ê¶Œì¥
            value="eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJ0eXBlIjoiQVBJIEtleSAtIFB1YmxpYyIsImV4cCI6MTc2NzIyNTU5OS4wfQ.kCXxCuJOs8__wVJdJqkeFz893I30HW5ai-hM1i4zaqE",
            type="password",
            key='api_key_tab1'
        )
        
        # ê²€ìƒ‰ ì„¤ì •
        company_name = st.text_input(
            "ë¶„ì„ ëŒ€ìƒ ê¸°ì—… (ì‰¼í‘œë¡œ ë™ì˜ì–´ êµ¬ë¶„)",
            placeholder="ì˜ˆ: ì‚¼ì„±ì „ì, ì‚¼ì„±",
            key='company_name_tab1'
        )
        
        # í¬ë¡¤ë§ ì„¤ì •
        col_setting1, col_setting2 = st.columns(2)
        
        with col_setting1:
            page_num = st.number_input(
                "í˜ì´ì§€ ìˆ˜",
                min_value=1,
                max_value=50,
                value=1,
                key='page_num_tab1',
                help="í¬ë¡¤ë§í•  í˜ì´ì§€ ìˆ˜ (1í˜ì´ì§€ = ì§€ì •í•œ ê°œìˆ˜ë§Œí¼ ë¬¸ì„œ)"
            )
        
        with col_setting2:
            crawl_size = st.number_input(
                "í˜ì´ì§€ë‹¹ ë¬¸ì„œ ìˆ˜",
                min_value=100,
                max_value=10000,
                value=1000,
                step=100,
                key='crawl_size_tab1',
                help="í•œ í˜ì´ì§€ë‹¹ ê°€ì ¸ì˜¬ ë¬¸ì„œ ìˆ˜ (ìµœëŒ€ 10,000ê°œ)"
            )
        
        st.info(f"ğŸ“Š ì´ ìµœëŒ€ ìˆ˜ì§‘ ë¬¸ì„œ ìˆ˜: **{page_num * crawl_size:,}ê°œ**")
        
        # ë‚ ì§œ ì„ íƒ
        col_date1, col_date2 = st.columns(2)
        
        default_start = datetime.now() - timedelta(days=365)
        default_end = datetime.now()
        
        with col_date1:
            start_date = st.date_input(
                "Start Date",
                value=default_start,
                key='start_date_tab1',
                help="ê²€ìƒ‰ ì‹œì‘ ë‚ ì§œ"
            )
        
        with col_date2:
            end_date = st.date_input(
                "End Date",
                value=default_end,
                key='end_date_tab1',
                help="ê²€ìƒ‰ ì¢…ë£Œ ë‚ ì§œ"
            )
        
        # í¬ë¡¤ë§ ë²„íŠ¼
        if st.button("í¬ë¡¤ë§ ë²„íŠ¼", use_container_width=True, key='crawl_button'):
            # --- ìœ íš¨ì„± ê²€ì‚¬ ---
            if not api_key:
                st.error("âŒ API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
                return
            if not company_name:
                st.error("âŒ ë¶„ì„ ëŒ€ìƒ ê¸°ì—…ì„ ì…ë ¥í•˜ì„¸ìš”.")
                return
            if start_date > end_date:
                st.error("âŒ Start Dateê°€ End Dateë³´ë‹¤ ë‚˜ì¤‘ì…ë‹ˆë‹¤. ë‚ ì§œë¥¼ ë‹¤ì‹œ í™•ì¸í•˜ì„¸ìš”.")
                return
            
            # --- í¬ë¡¤ë§ ì‹œì‘ ---
            st.markdown("### í¬ë¡¤ë§ ë¡œê·¸ ë° ìƒíƒœ ë°”")
            
            progress_bar = st.progress(0)
            status_text = st.empty()
            log_container = st.container()
            
            try:
                keywords = [k.strip() for k in company_name.split(',')]
                main_keyword = keywords[0]
                synonyms = keywords if len(keywords) > 1 else []
                
                status_text.text("ğŸ” í¬ë¡¤ë§ ì‹œì‘...")
                progress_bar.progress(10)
                
                with log_container:
                    st.text(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] í¬ë¡¤ë§ ì‹œì‘")
                    st.text(f"  - í‚¤ì›Œë“œ: {main_keyword}")
                    st.text(f"  - ë™ì˜ì–´: {', '.join(synonyms) if synonyms else 'ì—†ìŒ'}")
                    st.text(f"  - ê¸°ê°„: {start_date} ~ {end_date}")
                    st.text(f"  - í˜ì´ì§€ ìˆ˜: {page_num}")
                    st.text(f"  - í˜ì´ì§€ë‹¹ ë¬¸ì„œ ìˆ˜: {crawl_size:,}")
                
                # API í´ë¼ì´ì–¸íŠ¸ ìƒì„± (InsightPageAPIê°€ crawling.pyì—ì„œ importëœë‹¤ê³  ê°€ì •)
                api = InsightPageAPI(token=api_key)
                all_documents = []
                
                for page in range(page_num):
                    page_progress = 30 + (page / page_num * 60)
                    progress_bar.progress(int(page_progress))
                    
                    with log_container:
                        st.text(f"[{datetime.now().strftime('%H:%M:%S')}] í˜ì´ì§€ {page + 1}/{page_num} í¬ë¡¤ë§ ì¤‘...")
                    
                    # API í˜¸ì¶œ ì‹œ ë‚ ì§œë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬ ì „ë‹¬
                    result = api.get_documents(
                        start_date=start_date.strftime("%Y-%m-%d"),
                        end_date=end_date.strftime("%Y-%m-%d"),
                        keyword=main_keyword,
                        synonyms=synonyms,
                        size=crawl_size,
                        from_index=crawl_size * page + 1
                    )
                    
                    documents = result.get('documents', [])
                    
                    if not documents:
                        with log_container:
                            st.text(f"[{datetime.now().strftime('%H:%M:%S')}] í˜ì´ì§€ {page + 1}: ë°ì´í„° ì—†ìŒ - í¬ë¡¤ë§ ì¢…ë£Œ")
                        break
                    
                    all_documents.extend(documents)
                    
                    with log_container:
                        st.text(f"[{datetime.now().strftime('%H:%M:%S')}] í˜ì´ì§€ {page + 1}: {len(documents):,}ê°œ ë¬¸ì„œ ìˆ˜ì§‘")
                
                progress_bar.progress(100)
                status_text.text("âœ… í¬ë¡¤ë§ ì™„ë£Œ!")
                
                # --- ê²°ê³¼ í‘œì‹œ ë° ì €ì¥ ---
                if len(all_documents) > 0:
                    df = pd.DataFrame(all_documents)
                    st.session_state['crawled_data'] = df
                    st.session_state['crawled_keyword'] = main_keyword
                    st.session_state['crawled_time'] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                    
                    st.success(f"âœ… í¬ë¡¤ë§ ì™„ë£Œ! ì´ {len(all_documents):,}ê°œ ë¬¸ì„œë¥¼ ìˆ˜ì§‘í–ˆìŠµë‹ˆë‹¤.")
                    
                    st.markdown("---")
                    st.markdown("### ğŸ“‹ í¬ë¡¤ë§ ê²°ê³¼")
                    
                    col_info1, col_info2, col_info3 = st.columns(3)
                    with col_info1:
                        st.metric("ì´ ë¬¸ì„œ ìˆ˜", f"{len(df):,}ê°œ")
                    with col_info2:
                        st.metric("ì»¬ëŸ¼ ìˆ˜", f"{len(df.columns)}ê°œ")
                    with col_info3:
                        st.metric("í‚¤ì›Œë“œ", main_keyword)
                        
                    # ë¯¸ë¦¬ë³´ê¸° ë° ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ (ìì„¸í•œ ì½”ë“œëŠ” ìƒëµ)
                    st.dataframe(df.head(10), use_container_width=True)
                    # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ ë¡œì§ ...

                else:
                    st.warning("âš ï¸ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    
            except Exception as e:
                progress_bar.progress(0)
                status_text.text("âŒ í¬ë¡¤ë§ ì‹¤íŒ¨")
                st.error(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                with log_container:
                    st.text(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] ì˜¤ë¥˜ ë°œìƒ")
                    st.text(f"  - ì—ëŸ¬: {str(e)}")

        # ì´ì „ í¬ë¡¤ë§ ê²°ê³¼ê°€ ìˆìœ¼ë©´ í‘œì‹œ (ë¡œê·¸ê°€ ê¸¸ì–´ì§€ë¯€ë¡œ ê°„ëµí™”)
        if 'crawled_data' in st.session_state and st.session_state.get('crawled_data') is not None:
             st.markdown("---")
             st.markdown("### ğŸ’¾ ì €ì¥ëœ í¬ë¡¤ë§ ë°ì´í„°")
             st.info(f"ë§ˆì§€ë§‰ í¬ë¡¤ë§: í‚¤ì›Œë“œ '{st.session_state.get('crawled_keyword')}' ({len(st.session_state['crawled_data']):,}ê±´)")

    with tab2:
        st.markdown("### ğŸ§¹ í•™ìŠµ ë°ì´í„° ì¤€ë¹„ ë° ê²€í† ")
        
        # 1. ë°ì´í„° ë¡œë“œ í™•ì¸ ë° ì—…ë¡œë“œ ê¸°ëŠ¥
        if 'crawled_data' not in st.session_state or st.session_state['crawled_data'] is None:
            st.warning("âš ï¸ ë¨¼ì € 'í¬ë¡¤ë§API' íƒ­ì—ì„œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ê±°ë‚˜, CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì—¬ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì„¸ìš”.")
            
            # íŒŒì¼ ì—…ë¡œë“œ ì˜µì…˜
            uploaded_file = st.file_uploader("ë¡œì»¬ì—ì„œ ì „ì²˜ë¦¬ëœ í•™ìŠµ ë°ì´í„° CSV ì—…ë¡œë“œ", type=['csv'], key='train_upload')
            
            if uploaded_file is not None:
                # ì—…ë¡œë“œëœ ë°ì´í„°ë¥¼ ì„ì‹œë¡œ session_stateì— ì €ì¥í•˜ì—¬ ì‚¬ìš©
                try:
                    df_loaded = pd.read_csv(uploaded_file)
                    st.session_state['processed_data'] = df_loaded
                    st.success(f"âœ… íŒŒì¼ ë¡œë“œ ì™„ë£Œ. ì´ {len(df_loaded):,}ê°œ ë¬¸ì„œ.")
                except Exception as e:
                    st.error(f"íŒŒì¼ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            
            if st.session_state.get('processed_data') is None and st.session_state.get('crawled_data') is None:
                return # ë°ì´í„°ê°€ ì—†ìœ¼ë©´ íƒ­ ì§„í–‰ ì¤‘ë‹¨
        
        # í¬ë¡¤ë§ëœ ë°ì´í„° ë˜ëŠ” ì—…ë¡œë“œëœ ë°ì´í„° ì‚¬ìš©
        df = st.session_state.get('processed_data') if 'processed_data' in st.session_state else st.session_state.get('crawled_data')
        
        if df is None:
            return

        # 2. KPI Metrics (í˜„ì¬ ë°ì´í„° ìƒíƒœ)
        total_rows = len(df)
        # 'sentiment' ì»¬ëŸ¼ ì¡´ì¬ ì—¬ë¶€ë¡œ ë¼ë²¨ë§ ì™„ë£Œ ìƒíƒœ ì¶”ì • (1_ê°ì„±ë¼ë²¨ë¶€ì°©.ipynb ê²°ê³¼)
        has_sentiment = 'sentiment' in df.columns
        
        col_kpi1, col_kpi2, col_kpi3 = st.columns(3)
        with col_kpi1:
            st.metric("ì´ ë°ì´í„° í–‰ ìˆ˜", f"{total_rows:,} ê°œ")
        with col_kpi2:
            st.metric("ê°ì„± ë¼ë²¨ ì¡´ì¬ ì—¬ë¶€", "âœ… ìˆìŒ" if has_sentiment else "âŒ ì—†ìŒ")
        with col_kpi3:
            st.metric("ë‹¤ìŒ ë‹¨ê³„ ì¤€ë¹„ ìƒíƒœ", "âœ… í•™ìŠµ ì¤€ë¹„ ì™„ë£Œ" if has_sentiment else "âš ï¸ ë¼ë²¨ë§ ë‹¨ê³„ í•„ìš”")

        st.markdown("---")
        
        # 3. ë°ì´í„° í´ë¦¬ë‹/ì „ì²˜ë¦¬ ì„¤ì • (1_ê°ì„±ë¼ë²¨ë¶€ì°©.ipynb ë° ì „ì²˜ë¦¬ ë‹¨ê³„ ë°˜ì˜)
        st.markdown("### âš™ï¸ ë°ì´í„° í´ë¦¬ë‹ ë° ì „ì²˜ë¦¬ ì„¤ì •")
        with st.expander("ì „ì²˜ë¦¬ ì˜µì…˜ ì„¤ì • (ì‹¤ì œ ì ìš© ë¡œì§ì€ ë°±ì—”ë“œì—ì„œ êµ¬í˜„ í•„ìš”)", expanded=False):
            
            st.subheader("1. ì¤‘ë³µ/ë…¸ì´ì¦ˆ ì œê±°")
            col_clean1, col_clean2 = st.columns(2)
            with col_clean1:
                dedup_option = st.checkbox("ë¬¸ì„œ ì¤‘ë³µ ì œê±°", value=True, help="ì œëª©/ë³¸ë¬¸ì´ ì™„ì „íˆ ë™ì¼í•œ ë¬¸ì„œë¥¼ ì œê±°í•©ë‹ˆë‹¤.")
                short_filter = st.slider("ìµœì†Œ ê¸¸ì´ í•„í„° (ë‹¨ì–´)", min_value=5, max_value=50, value=10, help="ì´ ê¸¸ì´ ë¯¸ë§Œì˜ ë¬¸ì¥ì„ ì œê±°í•©ë‹ˆë‹¤.", key='min_len_filter')
            with col_clean2:
                # ë¶ˆìš©ì–´ ì²˜ë¦¬ ì„¤ì •
                st.text_area("ì¶”ê°€ ë¶ˆìš©ì–´ ëª©ë¡", value="ê¸°ì, ê´€ë ¨, ì´ë‚ , í˜„ì¬, ê²ƒìœ¼ë¡œ", height=100, key='stopwords_list')
                
            st.subheader("2. í…ìŠ¤íŠ¸ ì •ê·œí™”")
            normalize_text = st.checkbox("ë¬¸ì ì •ê·œí™” (ì´ëª¨ì§€, íŠ¹ìˆ˜ê¸°í˜¸)", value=True, key='normalize_check')

        st.markdown("---")
        
        # 4. ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°
        st.markdown("### ğŸ“‹ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°")
        st.dataframe(df.head(10), use_container_width=True)
        
        # 5. ìµœì¢… ì‘ì—… ë²„íŠ¼
        st.markdown("---")
        
        # ë°ì´í„°í”„ë ˆì„ì„ CSVë¡œ ë³€í™˜ (ë‹¤ìš´ë¡œë“œë¥¼ ìœ„í•´)
        csv_data = df.to_csv(index=False, encoding='utf-8-sig')
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"training_data_{timestamp}.csv"
        
        st.download_button(
            label="ğŸ’¾ ì „ì²˜ë¦¬ëœ í•™ìŠµ ë°ì´í„° ë‹¤ìš´ë¡œë“œ (CSV)", 
            data=csv_data,
            file_name=filename,
            mime="text/csv",
            use_container_width=True,
            type='secondary'
        )
        st.caption("ì´ íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•˜ì—¬ `1_ê°ì„±ë¼ë²¨ë¶€ì°©.ipynb` ë“±ì˜ í•™ìŠµ ë‹¨ê³„ì— ì‚¬ìš©í•˜ì„¸ìš”.")


if __name__ == "__main__":
    main()