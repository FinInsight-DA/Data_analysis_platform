# -*- coding: utf-8 -*-
"""
LDA í† í”½ ëª¨ë¸ë§ ìë™í™” Streamlit ì•± (ë¶„ì„ê°€ìš©)
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import time
import pickle
import hashlib
import json
import re
from io import BytesIO
from datetime import datetime
from pathlib import Path

# KoNLPy & Gensim
from konlpy.tag import Okt
from gensim import corpora
from gensim.models import LdaModel, CoherenceModel
from tqdm import tqdm

# ============================================================================
# í˜ì´ì§€ ì„¤ì •
# ============================================================================
st.set_page_config(
    page_title="LDA í† í”½ ëª¨ë¸ë§",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ============================================================================
# CSS ìŠ¤íƒ€ì¼
# ============================================================================
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
    }
    .sub-header {
        font-size: 1.5rem;
        font-weight: bold;
        color: #2c3e50;
        margin-top: 2rem;
        margin-bottom: 1rem;
    }
    .metric-card {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 0.5rem 0;
    }
</style>
""", unsafe_allow_html=True)

# ============================================================================
# ê¸°ë³¸ ë¶ˆìš©ì–´
# ============================================================================
DEFAULT_STOP_WORDS = {
    'ì€', 'ëŠ”', 'ì´', 'ê°€', 'ì„', 'ë¥¼', 'ì˜', 'ì™€', 'ê³¼', 'ë„',
    'ì—', 'ë¡œ', 'ì—ì„œ', 'ë¶€í„°', 'ê¹Œì§€',
    'í•˜ë‹¤', 'ìˆë‹¤', 'ë˜ë‹¤', 'ê°™ë‹¤', 'ì—†ë‹¤',
    'ê²ƒ', 'ìˆ˜', 'ë“±', 'ê°œ', 'ëª…', 'ë…„', 'ì›”', 'ì¼',
    'ì—…ê³„', 'ê¸°ì—…', 'íšŒì‚¬', 'ì—…ì²´', 'ê´€ê³„ì',
    'ì˜¬í•´', 'ë‚´ë…„', 'ì‘ë…„', 'ì´ë²ˆ', 'ì§€ë‚œí•´', 'ìµœê·¼'
}

# ============================================================================
# LDA í´ë˜ìŠ¤
# ============================================================================
class LDATopicModeling:
    """LDA í† í”½ ëª¨ë¸ë§"""
    
    def __init__(self, df, stop_words, min_noun_length=2):
        self.df = df
        self.stop_words = stop_words
        self.min_noun_length = min_noun_length
        self.processed_sentences = None
        self.valid_indices = None  # ìœ íš¨í•œ ë¬¸ì¥ì˜ ì›ë³¸ ì¸ë±ìŠ¤ ì €ì¥
        self.dictionary = None
        self.corpus = None
        self.models = {}
        self.topics_dict = {}
        self.coherence_scores = {}
        self.perplexity_scores = {}  # Perplexity ì¶”ê°€
    
    def preprocess(self, use_cache=True):
        """í˜•íƒœì†Œ ë¶„ì„"""
        if use_cache and 'preprocessed_data' in st.session_state:
            self.processed_sentences = st.session_state['preprocessed_data']
            self.valid_indices = st.session_state['valid_indices']
            return
        
        okt = Okt()
        
        def clean_text(text):
            if pd.isna(text):
                return []
            text = re.sub(r'[^ê°€-í£a-zA-Z0-9\s]', '', str(text))
            try:
                nouns = okt.nouns(text)
                return [
                    n for n in nouns
                    if len(n) >= self.min_noun_length
                    and not n.isdigit()
                    and n not in self.stop_words
                ]
            except:
                return []
        
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        all_processed = []
        valid_indices = []
        
        for i, text in enumerate(self.df['sentence']):
            cleaned = clean_text(text)
            all_processed.append(cleaned)
            if len(cleaned) > 0:
                valid_indices.append(i)
            
            if i % 100 == 0:
                progress_bar.progress((i + 1) / len(self.df))
                status_text.text(f"í˜•íƒœì†Œ ë¶„ì„ ì¤‘... {i+1}/{len(self.df)}")
        
        progress_bar.progress(1.0)
        status_text.text(f"í˜•íƒœì†Œ ë¶„ì„ ì™„ë£Œ: {len(self.df):,}ê°œ")
        
        # ìœ íš¨í•œ ë¬¸ì¥ë§Œ ì €ì¥
        self.processed_sentences = [all_processed[i] for i in valid_indices]
        self.valid_indices = valid_indices
        
        # ìºì‹œ ì €ì¥
        st.session_state['preprocessed_data'] = self.processed_sentences
        st.session_state['valid_indices'] = self.valid_indices
    
    def create_dict_corpus(self, no_below, no_above, keep_n):
        """Dictionary & Corpus ìƒì„±"""
        self.dictionary = corpora.Dictionary(self.processed_sentences)
        original_size = len(self.dictionary)
        
        self.dictionary.filter_extremes(
            no_below=no_below,
            no_above=no_above,
            keep_n=keep_n
        )
        
        self.corpus = [self.dictionary.doc2bow(text) for text in self.processed_sentences]
        
        return original_size, len(self.dictionary)
    
    def train_lda(self, n_topics, passes, iterations, alpha, eta):
        """LDA í•™ìŠµ"""
        model = LdaModel(
            corpus=self.corpus,
            id2word=self.dictionary,
            num_topics=n_topics,
            passes=passes,
            iterations=iterations,
            random_state=42,
            per_word_topics=False,
            alpha=alpha,
            eta=eta
        )
        
        self.models[n_topics] = model
        
        # í† í”½ í• ë‹¹
        doc_topics = []
        for bow in self.corpus:
            topic_dist = model.get_document_topics(bow)
            if topic_dist:
                dominant = max(topic_dist, key=lambda x: x[1])[0]
                doc_topics.append(dominant)
            else:
                doc_topics.append(-1)
        
        self.topics_dict[n_topics] = np.array(doc_topics)
        
        # Coherence ê³„ì‚°
        coherence_model = CoherenceModel(
            model=model,
            texts=self.processed_sentences,
            dictionary=self.dictionary,
            coherence='c_v'
        )
        coherence = coherence_model.get_coherence()
        self.coherence_scores[n_topics] = coherence
        
        # Perplexity ê³„ì‚°
        perplexity = model.log_perplexity(self.corpus)
        self.perplexity_scores[n_topics] = perplexity
        
        return coherence, perplexity
    
    def get_result_df(self, n_topics):
        """ê²°ê³¼ ë°ì´í„°í”„ë ˆì„ ìƒì„±"""
        topics = self.topics_dict[n_topics]
        
        # ìœ íš¨í•œ ì¸ë±ìŠ¤ë§Œ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°í”„ë ˆì„ ìƒì„±
        result_df = self.df.iloc[self.valid_indices].copy()
        result_df['lda_topic'] = topics
        
        # í† í”½ì´ í• ë‹¹ë˜ì§€ ì•Šì€ ë¬¸ì„œ ì œê±°
        result_df = result_df[result_df['lda_topic'] != -1]
        
        return result_df

# ============================================================================
# ì—˜ë³´ìš° í¬ì¸íŠ¸ ê³„ì‚° í•¨ìˆ˜
# ============================================================================
def calculate_elbow_point(scores_dict, maximize=True):
    """
    ì—˜ë³´ìš° í¬ì¸íŠ¸ ê³„ì‚° 
    
    Parameters:
    - scores_dict: {n_topics: score} ë”•ì…”ë„ˆë¦¬
    - maximize: Trueë©´ ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ (Coherence), Falseë©´ ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ (Perplexity)
    
    Returns:
    - elbow_point: ìµœì  í† í”½ ê°œìˆ˜
    """
    if len(scores_dict) < 3:
        return None
    
    topics = np.array(sorted(scores_dict.keys()))
    scores = np.array([scores_dict[k] for k in topics])
    
    if not maximize:
        scores = -scores  # PerplexityëŠ” ë‚®ì„ìˆ˜ë¡ ì¢‹ìœ¼ë¯€ë¡œ ë¶€í˜¸ ë°˜ì „
    
    # ì •ê·œí™” (0-1 ë²”ìœ„ë¡œ)
    scores_norm = (scores - scores.min()) / (scores.max() - scores.min() + 1e-10)
    topics_norm = (topics - topics.min()) / (topics.max() - topics.min() + 1e-10)
    
    # ì‹œì‘ì ê³¼ ëì ì„ ì‡ëŠ” ì§ì„ ê¹Œì§€ì˜ ê±°ë¦¬ ê³„ì‚°
    # ì§ì„ : y = mx + b
    m = (scores_norm[-1] - scores_norm[0]) / (topics_norm[-1] - topics_norm[0] + 1e-10)
    b = scores_norm[0]
    
    # ê° ì ì—ì„œ ì§ì„ ê¹Œì§€ì˜ ìˆ˜ì§ ê±°ë¦¬
    distances = np.abs(scores_norm - (m * topics_norm + b)) / np.sqrt(m**2 + 1)
    
    # ê°€ì¥ ë¨¼ ì ì´ ì—˜ë³´ìš° í¬ì¸íŠ¸
    elbow_idx = np.argmax(distances)
    elbow_point = topics[elbow_idx]
    
    return int(elbow_point)

# ============================================================================
# ì‹œê°í™” í•¨ìˆ˜
# ============================================================================
def create_metrics_comparison_chart(coherence_scores, perplexity_scores):
    """Coherence & Perplexity ë¹„êµ ì°¨íŠ¸ - íŒŒë€ìƒ‰ ê³„ì—´ë¡œ í†µì¼"""
    from plotly.subplots import make_subplots
    
    # ì—˜ë³´ìš° í¬ì¸íŠ¸ ê³„ì‚° (íš¨ìœ¨ì„± ê· í˜•ì )
    coherence_elbow = calculate_elbow_point(coherence_scores, maximize=True)
    perplexity_elbow = calculate_elbow_point(perplexity_scores, maximize=False)
    
    # ìµœê³  ì„±ëŠ¥ ê°’ ê³„ì‚°
    best_coherence_topic = max(coherence_scores.keys(), key=lambda k: coherence_scores[k])
    best_perplexity_topic = min(perplexity_scores.keys(), key=lambda k: perplexity_scores[k])
    
    fig = make_subplots(
        rows=1, cols=2,
        subplot_titles=(
            f'Coherence (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ) - ğŸ”·íš¨ìœ¨: {coherence_elbow}ê°œ, ğŸ”µìµœê³ : {best_coherence_topic}ê°œ',
            f'Perplexity (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ) - ğŸ”·íš¨ìœ¨: {perplexity_elbow}ê°œ, ğŸ”µìµœê³ : {best_perplexity_topic}ê°œ'
        ),
        horizontal_spacing=0.15
    )
    
    # Coherence ë°” ì°¨íŠ¸ - íŒŒë€ìƒ‰ ê³„ì—´ë¡œ í†µì¼
    colors_coherence = []
    for k in coherence_scores.keys():
        if k == best_coherence_topic and k == coherence_elbow:
            colors_coherence.append('#0D47A1')  # ë‘˜ ë‹¤ í•´ë‹¹ - ê°€ì¥ ì§„í•œ íŒŒë‘
        elif k == coherence_elbow:
            colors_coherence.append('#64B5F6')  # íš¨ìœ¨ì„± - ë°ì€ íŒŒë‘ (ê³¨ë“œ ëŒ€ì‹ )
        elif k == best_coherence_topic:
            colors_coherence.append('#1565C0')  # ìµœê³  ì„±ëŠ¥ - ì§„í•œ íŒŒë‘
        else:
            colors_coherence.append('#90CAF9')  # ì¼ë°˜ - ì—°í•œ íŒŒë‘
    
    fig.add_trace(
        go.Bar(
            x=list(coherence_scores.keys()),
            y=list(coherence_scores.values()),
            text=[f"{v:.4f}" for v in coherence_scores.values()],
            textposition='auto',
            textfont=dict(color='white', size=11, family='Arial'),
            marker_color=colors_coherence,
            marker_line=dict(width=1.5, color='white'),
            name='Coherence'
        ),
        row=1, col=1
    )
    
    # Perplexity ë°” ì°¨íŠ¸ - íŒŒë€ìƒ‰ ê³„ì—´ë¡œ í†µì¼
    colors_perplexity = []
    for k in perplexity_scores.keys():
        if k == best_perplexity_topic and k == perplexity_elbow:
            colors_perplexity.append('#0D47A1')  # ë‘˜ ë‹¤ í•´ë‹¹ - ê°€ì¥ ì§„í•œ íŒŒë‘
        elif k == perplexity_elbow:
            colors_perplexity.append('#64B5F6')  # íš¨ìœ¨ì„± - ë°ì€ íŒŒë‘
        elif k == best_perplexity_topic:
            colors_perplexity.append('#1565C0')  # ìµœê³  ì„±ëŠ¥ - ì§„í•œ íŒŒë‘
        else:
            colors_perplexity.append('#90CAF9')  # ì¼ë°˜ - ì—°í•œ íŒŒë‘
    
    fig.add_trace(
        go.Bar(
            x=list(perplexity_scores.keys()),
            y=list(perplexity_scores.values()),
            text=[f"{v:.2f}" for v in perplexity_scores.values()],
            textposition='auto',
            textfont=dict(color='white', size=11, family='Arial'),
            marker_color=colors_perplexity,
            marker_line=dict(width=1.5, color='white'),
            name='Perplexity'
        ),
        row=1, col=2
    )
    
    fig.update_xaxes(title_text="í† í”½ ê°œìˆ˜", row=1, col=1)
    fig.update_xaxes(title_text="í† í”½ ê°œìˆ˜", row=1, col=2)
    fig.update_yaxes(title_text="Coherence", row=1, col=1)
    fig.update_yaxes(title_text="Perplexity", row=1, col=2)
    
    fig.update_layout(
        height=450,
        showlegend=False,
        title_text="í† í”½ ê°œìˆ˜ë³„ í‰ê°€ ì§€í‘œ ë¹„êµ (ğŸ”·=íš¨ìœ¨ì„± ê· í˜•ì , ğŸ”µ=ìµœê³  ì„±ëŠ¥)",
        title_font=dict(size=16, color='#1565C0', family='Arial'),
        plot_bgcolor='#FAFAFA',
        paper_bgcolor='white',
        font=dict(family='Arial', color='#37474F')
    )
    
    # ê·¸ë¦¬ë“œ ë¼ì¸ ìŠ¤íƒ€ì¼
    fig.update_xaxes(
        gridcolor='#E0E0E0',
        gridwidth=0.5,
        showline=True,
        linewidth=1,
        linecolor='#BDBDBD'
    )
    fig.update_yaxes(
        gridcolor='#E0E0E0',
        gridwidth=0.5,
        showline=True,
        linewidth=1,
        linecolor='#BDBDBD'
    )
    
    return fig

def create_coherence_chart(coherence_scores):
    """Coherence ì ìˆ˜ ë¹„êµ ì°¨íŠ¸ (í˜¸í™˜ì„± ìœ ì§€)"""
    # íŒŒë€ìƒ‰ ê³„ì—´ ê·¸ë¼ë°ì´ì…˜ ìƒì„±
    n = len(coherence_scores)
    colors = []
    for i in range(n):
        ratio = i / max(n - 1, 1)
        r = int(26 + (179 - 26) * ratio)   # 26(#1a) â†’ 179(#b3)
        g = int(84 + (217 - 84) * ratio)   # 84(#54) â†’ 217(#d9)
        b = int(144 + (255 - 144) * ratio) # 144(#90) â†’ 255(#ff)
        colors.append(f'rgb({r},{g},{b})')
    
    fig = go.Figure(data=[
        go.Bar(
            x=list(coherence_scores.keys()),
            y=list(coherence_scores.values()),
            text=[f"{v:.4f}" for v in coherence_scores.values()],
            textposition='auto',
            marker=dict(
                color=colors,
                line=dict(color='white', width=2)
            )
        )
    ])
    
    fig.update_layout(
        title=dict(
            text='í† í”½ ê°œìˆ˜ë³„ Coherence ì ìˆ˜',
            font=dict(size=18, color='#2c3e50', family='Arial'),
            x=0.5,
            xanchor='center'
        ),
        xaxis=dict(
            title='í† í”½ ê°œìˆ˜',
            tickfont=dict(size=12, color='#2c3e50'),
            showgrid=False,
            showline=False
        ),
        yaxis=dict(
            title='Coherence ì ìˆ˜',
            title_font=dict(size=13, color='#7f8c8d'),
            tickfont=dict(size=12, color='#7f8c8d'),
            showgrid=True,
            gridwidth=1,
            gridcolor='#ecf0f1',
            showline=False
        ),
        height=400,
        plot_bgcolor='white',
        paper_bgcolor='white'
    )
    
    return fig

def create_topic_distribution_chart(result_df):
    """í† í”½ë³„ ë¬¸ì„œ ìˆ˜ ë¶„í¬ - íŒŒë€ìƒ‰ ê³„ì—´ ê·¸ë¼ë°ì´ì…˜"""
    topic_counts = result_df['lda_topic'].value_counts().sort_index()
    
    # íŒŒë€ìƒ‰ ê³„ì—´ ê·¸ë¼ë°ì´ì…˜ ìƒì„±
    n = len(topic_counts)
    colors = []
    for i in range(n):
        ratio = i / max(n - 1, 1)
        r = int(26 + (179 - 26) * ratio)   # 26(#1a) â†’ 179(#b3)
        g = int(84 + (217 - 84) * ratio)   # 84(#54) â†’ 217(#d9)
        b = int(144 + (255 - 144) * ratio) # 144(#90) â†’ 255(#ff)
        colors.append(f'rgb({r},{g},{b})')
    
    fig = go.Figure(data=[
        go.Bar(
            x=topic_counts.index,
            y=topic_counts.values,
            text=topic_counts.values,
            textposition='auto',
            textfont=dict(color='white', size=11, family='Arial'),
            marker=dict(
                color=colors,
                line=dict(width=1.5, color='white')
            )
        )
    ])
    
    fig.update_layout(
        title=dict(
            text='í† í”½ë³„ ë¬¸ì„œ ìˆ˜',
            font=dict(size=18, color='#2c3e50', family='Arial'),
            x=0.5,
            xanchor='center'
        ),
        xaxis=dict(
            title='í† í”½ ë²ˆí˜¸',
            tickfont=dict(size=12, color='#2c3e50'),
            showgrid=False,
            showline=False
        ),
        yaxis=dict(
            title='ë¬¸ì„œ ìˆ˜',
            title_font=dict(size=13, color='#7f8c8d'),
            tickfont=dict(size=12, color='#7f8c8d'),
            showgrid=True,
            gridwidth=1,
            gridcolor='#ecf0f1',
            showline=False
        ),
        height=400,
        plot_bgcolor='white',
        paper_bgcolor='white'
    )
    
    return fig

def create_topic_keywords_table(model, n_topics, top_n=10):
    """í† í”½ë³„ í‚¤ì›Œë“œ í…Œì´ë¸”"""
    data = []
    for topic_id in range(n_topics):
        words = model.show_topic(topic_id, topn=top_n)
        keywords = ', '.join([f"{word}({prob:.3f})" for word, prob in words[:5]])
        data.append({
            'í† í”½': f"Topic {topic_id}",
            'ì£¼ìš” í‚¤ì›Œë“œ': keywords
        })
    
    return pd.DataFrame(data)

# ============================================================================
# ë©”ì¸ ì•±
# ============================================================================
def main():
    # í—¤ë”
    st.markdown('<div class="main-header">LDA í† í”½ ëª¨ë¸ë§</div>', unsafe_allow_html=True)
    st.markdown("---")
    
    # ============================================================================
    # 1. íŒŒì¼ ì—…ë¡œë“œ
    # ============================================================================
    st.markdown('<div class="sub-header">ğŸ“ 1. ë°ì´í„° ì—…ë¡œë“œ</div>', unsafe_allow_html=True)
    
    uploaded_file = st.file_uploader(
        "CSV íŒŒì¼ ì—…ë¡œë“œ (sentence ì»¬ëŸ¼ í•„ìˆ˜)",
        type=['csv'],
        help="LDA í† í”½ ëª¨ë¸ë§ì„ ìˆ˜í–‰í•  CSV íŒŒì¼"
    )
    
    # ============================================================================
    # íŒŒì¼ ë³€ê²½ ê°ì§€ ë° ìºì‹œ ì´ˆê¸°í™”
    # ============================================================================
    current_file_name = uploaded_file.name if uploaded_file else None
    
    if 'prev_file_name' not in st.session_state:
        st.session_state['prev_file_name'] = None
    
    # íŒŒì¼ì´ ë°”ë€Œë©´ ìºì‹œ ì´ˆê¸°í™”
    if current_file_name != st.session_state['prev_file_name']:
        if 'preprocessed_data' in st.session_state:
            del st.session_state['preprocessed_data']
        if 'valid_indices' in st.session_state:
            del st.session_state['valid_indices']
        if 'lda' in st.session_state:
            del st.session_state['lda']
        if 'results' in st.session_state:
            del st.session_state['results']
        
        st.session_state['prev_file_name'] = current_file_name
    
    if uploaded_file is None:
        st.info("â¬†ï¸ CSV íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
        return
    
    # ë°ì´í„° ë¡œë“œ
    try:
        df = pd.read_csv(uploaded_file)
        st.markdown(f"""
        <div style="background-color: #F0F2F6; padding: 1rem; border-radius: 0.5rem; margin-bottom: 1rem;">
            âœ… <strong>ë°ì´í„° ë¡œë“œ ì™„ë£Œ:</strong> {len(df):,}ê°œ ë¬¸ì„œ
        </div>
        """, unsafe_allow_html=True)
        
        if 'sentence' not in df.columns:
            st.error("âŒ 'sentence' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return
        
    except Exception as e:
        st.error(f"âŒ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return
    
    st.markdown("---")
    
    # ============================================================================
    # 2. íŒŒë¼ë¯¸í„° ì„¤ì •
    # ============================================================================
    st.markdown('<div class="sub-header">âš™ï¸ 2. íŒŒë¼ë¯¸í„° ì„¤ì •</div>', unsafe_allow_html=True)
    
    # í† í”½ ê°œìˆ˜
    st.markdown("**í† í”½ ê°œìˆ˜ ì„¤ì •**")
    col1, col2 = st.columns([3, 1])
    
    with col1:
        topic_numbers_input = st.text_input(
            "í•™ìŠµí•  í† í”½ ê°œìˆ˜ (ì‰¼í‘œë¡œ êµ¬ë¶„)",
            value="5, 10, 15, 20",
            help="ì˜ˆ: 5, 10, 15, 20"
        )
    
    with col2:
        try:
            topic_numbers = [int(x.strip()) for x in topic_numbers_input.split(',')]
            st.info(f"{len(topic_numbers)}ê°œ ì„¤ì •")
        except:
            st.error("ìˆ«ìì™€ ì‰¼í‘œë§Œ ì…ë ¥")
            return
    
    st.markdown("---")
    
    # LDA í•˜ì´í¼íŒŒë¼ë¯¸í„°
    st.markdown("**LDA í•˜ì´í¼íŒŒë¼ë¯¸í„°**")
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        passes = st.slider("Passes", 1, 50, 10, help="ì „ì²´ ì½”í¼ìŠ¤ë¥¼ ëª‡ ë²ˆ ë°˜ë³µí• ì§€")
    
    with col2:
        iterations = st.slider("Iterations", 50, 500, 100, help="ê° ë¬¸ì„œë¥¼ ëª‡ ë²ˆ ì—…ë°ì´íŠ¸í• ì§€")
    
    with col3:
        alpha_mode = st.radio(
            "Alpha ì„¤ì •",
            options=['auto', 'symmetric', 'asymmetric', 'manual'],
            horizontal=True,
            help="ëª¨ë¸ í•™ìŠµ ë°©ì‹ ì„ íƒ"
        )
        
        if alpha_mode == 'auto':
            alpha = 'auto'
            st.caption("âœ… ë°ì´í„°ë¡œë¶€í„° ìë™ ìµœì í™”")
        elif alpha_mode == 'symmetric':
            alpha = 'symmetric'
            st.caption("âœ… ëª¨ë“  í† í”½ ë™ì¼ ê°€ì¤‘ì¹˜ (1/K)")
        elif alpha_mode == 'asymmetric':
            alpha = 'asymmetric'
            st.caption("âœ… í† í”½ë³„ ë‹¤ë¥¸ ê°€ì¤‘ì¹˜ (ìë™)")
        else:  # manual
            alpha = st.number_input(
                "Alpha ê°’",
                min_value=0.001,
                max_value=10.0,
                value=0.1,
                step=0.01,
                format="%.3f",
                help="ë¬¸ì„œ-í† í”½ ë¶„í¬. ë‚®ì„ìˆ˜ë¡ ë¬¸ì„œê°€ ì ì€ í† í”½ì— ì§‘ì¤‘"
            )
            st.caption(f"í˜„ì¬ê°’: {alpha}")
    
    with col4:
        eta_mode = st.radio(
            "Eta (Beta) ì„¤ì •",
            options=['auto', 'symmetric', 'manual'],
            horizontal=True,
            help="ëª¨ë¸ í•™ìŠµ ë°©ì‹ ì„ íƒ"
        )
        
        if eta_mode == 'auto':
            eta = 'auto'
            st.caption("âœ… ë°ì´í„°ë¡œë¶€í„° ìë™ ìµœì í™”")
        elif eta_mode == 'symmetric':
            eta = 'symmetric'
            st.caption("âœ… ëª¨ë“  ë‹¨ì–´ ë™ì¼ ê°€ì¤‘ì¹˜ (1/V)")
        else:  # manual
            eta = st.number_input(
                "Eta ê°’",
                min_value=0.001,
                max_value=10.0,
                value=0.01,
                step=0.01,
                format="%.3f",
                help="í† í”½-ë‹¨ì–´ ë¶„í¬. ë‚®ì„ìˆ˜ë¡ í† í”½ì´ ì ì€ ë‹¨ì–´ì— ì§‘ì¤‘"
            )
            st.caption(f"í˜„ì¬ê°’: {eta}")
    
    st.markdown("---")
    
    # Dictionary í•„í„°ë§
    st.markdown("**Dictionary í•„í„°ë§**")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        no_below = st.number_input(
            "no_below",
            min_value=1,
            max_value=100,
            value=5,
            help="ìµœì†Œ ë¬¸ì„œ ì¶œí˜„ ë¹ˆë„"
        )
    
    with col2:
        no_above = st.slider(
            "no_above",
            0.0, 1.0, 0.5,
            help="ìµœëŒ€ ë¬¸ì„œ ì¶œí˜„ ë¹„ìœ¨"
        )
    
    with col3:
        keep_n = st.number_input(
            "keep_n",
            min_value=1000,
            max_value=100000,
            value=10000,
            step=1000,
            help="ìœ ì§€í•  ìµœëŒ€ ë‹¨ì–´ ìˆ˜"
        )
    
    st.markdown("---")
    
    # ë¶ˆìš©ì–´ ê´€ë¦¬
    st.markdown("**ë¶ˆìš©ì–´ ê´€ë¦¬**")
    
    with st.expander("ğŸ“ ë¶ˆìš©ì–´ í¸ì§‘ (ì„ íƒì‚¬í•­)"):
        st.write("**í˜„ì¬ ê¸°ë³¸ ë¶ˆìš©ì–´:**")
        stop_words_text = st.text_area(
            "ë¶ˆìš©ì–´ ëª©ë¡ (ì‰¼í‘œë¡œ êµ¬ë¶„)",
            value=', '.join(sorted(DEFAULT_STOP_WORDS)),
            height=150,
            help="ë¶ˆìš©ì–´ë¥¼ ì‰¼í‘œë¡œ êµ¬ë¶„í•˜ì—¬ ì…ë ¥í•˜ì„¸ìš”"
        )
        
        stop_words = set([w.strip() for w in stop_words_text.split(',') if w.strip()])
        st.info(f"âœ… ì´ {len(stop_words)}ê°œ ë¶ˆìš©ì–´ ì„¤ì •")
    
    # í˜•íƒœì†Œ ë¶„ì„ ì˜µì…˜
    col1, col2 = st.columns(2)
    
    with col1:
        min_noun_length = st.slider(
            "ìµœì†Œ ëª…ì‚¬ ê¸¸ì´",
            1, 5, 2,
            help="ì´ ê¸¸ì´ë³´ë‹¤ ì§§ì€ ëª…ì‚¬ëŠ” ì œì™¸"
        )
    
    with col2:
        use_cache = st.checkbox(
            "ìºì‹œ ì‚¬ìš©",
            value=True,
            help="ì´ì „ í˜•íƒœì†Œ ë¶„ì„ ê²°ê³¼ ì¬ì‚¬ìš©"
        )
    
    # íŒŒë¼ë¯¸í„° ìš”ì•½
    with st.expander("ğŸ“‹ ì„¤ì • ìš”ì•½"):
        st.write(f"""
        **í† í”½ ê°œìˆ˜:** {', '.join(map(str, topic_numbers))}
        
        **LDA íŒŒë¼ë¯¸í„°:**
        - Passes: {passes}
        - Iterations: {iterations}
        - Alpha: {alpha}
        - Eta: {eta}
        
        **Dictionary í•„í„°:**
        - no_below: {no_below}
        - no_above: {no_above}
        - keep_n: {keep_n:,}
        
        **ì „ì²˜ë¦¬:**
        - ìµœì†Œ ëª…ì‚¬ ê¸¸ì´: {min_noun_length}
        - ë¶ˆìš©ì–´: {len(stop_words)}ê°œ
        """)
    
    st.markdown("---")
    
    # ============================================================================
    # 3. í•™ìŠµ ì‹¤í–‰
    # ============================================================================
    st.markdown('<div class="sub-header">ğŸš€ 3. í•™ìŠµ ì‹¤í–‰</div>', unsafe_allow_html=True)
    
    if st.button("í•™ìŠµ ì‹œì‘", type="primary", use_container_width=True):
        start_time = time.time()
        
        # ì´ˆê¸°í™”
        lda = LDATopicModeling(df, stop_words, min_noun_length)
        
        # ì „ì²˜ë¦¬
        with st.spinner("í˜•íƒœì†Œ ë¶„ì„ ì¤‘..."):
            lda.preprocess(use_cache=use_cache)
        
        st.markdown(f"""
        <div style="background-color: #F0F2F6; padding: 1rem; border-radius: 0.5rem; margin-bottom: 1rem;">
            âœ… <strong>ì „ì²˜ë¦¬ ì™„ë£Œ:</strong> {len(lda.processed_sentences):,}ê°œ ë¬¸ì¥
        </div>
        """, unsafe_allow_html=True)
        
        # Dictionary & Corpus
        with st.spinner("Dictionary & Corpus ìƒì„± ì¤‘..."):
            original_size, filtered_size = lda.create_dict_corpus(no_below, no_above, keep_n)
        
        st.markdown(f"""
        <div style="background-color: #F0F2F6; padding: 1rem; border-radius: 0.5rem; margin-bottom: 1rem;">
            âœ… <strong>Dictionary ìƒì„± ì™„ë£Œ</strong><br>
            ì›ë³¸: {original_size:,}ê°œ â†’ í•„í„°ë§ í›„: {filtered_size:,}ê°œ
        </div>
        """, unsafe_allow_html=True)
        
        # í•™ìŠµ
        st.markdown("**LDA í•™ìŠµ ì§„í–‰**")
        
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        results = []
        
        for i, n_topics in enumerate(topic_numbers):
            status_text.text(f"í•™ìŠµ ì¤‘: {n_topics}ê°œ í† í”½...")
            
            with st.spinner(f"{n_topics}ê°œ í† í”½ í•™ìŠµ ì¤‘..."):
                coherence, perplexity = lda.train_lda(n_topics, passes, iterations, alpha, eta)
            
            results.append({
                'í† í”½ ê°œìˆ˜': n_topics,
                'Coherence': f"{coherence:.4f}",
                'Perplexity': f"{perplexity:.2f}",
                'ë¬¸ì„œ ìˆ˜': f"{(lda.topics_dict[n_topics] != -1).sum():,}"
            })
            
            progress_bar.progress((i + 1) / len(topic_numbers))
        
        status_text.text("âœ… ëª¨ë“  í•™ìŠµ ì™„ë£Œ!")
        
        # ê²°ê³¼ ì €ì¥
        st.session_state['lda'] = lda
        st.session_state['results'] = results
        
        # ì‹¤í–‰ ì‹œê°„
        elapsed = time.time() - start_time
        st.markdown(f"""
        <div style="background-color: #F0F2F6; padding: 1rem; border-radius: 0.5rem; margin-bottom: 1rem;">
            ğŸ‰ <strong>í•™ìŠµ ì™„ë£Œ!</strong> (ì´ ì†Œìš” ì‹œê°„: {elapsed/60:.1f}ë¶„)
        </div>
        """, unsafe_allow_html=True)
        
        st.markdown("---")
    
    # ============================================================================
    # 4. ê²°ê³¼ ì¶œë ¥
    # ============================================================================
    if 'lda' in st.session_state:
        lda = st.session_state['lda']
        results = st.session_state['results']
        
        st.markdown('<div class="sub-header">ğŸ“Š 3. í•™ìŠµ ê²°ê³¼</div>', unsafe_allow_html=True)
        
        # ì „ì²´ ìš”ì•½
        st.markdown("**í•™ìŠµ ìš”ì•½**")
        st.dataframe(pd.DataFrame(results), use_container_width=True)
        
        # Coherence & Perplexity ë¹„êµ
        st.markdown("---")
        st.markdown("**í‰ê°€ ì§€í‘œ ë¹„êµ**")
        
        # ì—˜ë³´ìš° í¬ì¸íŠ¸ ê³„ì‚° (íš¨ìœ¨ì„± ê· í˜•ì )
        coherence_elbow = calculate_elbow_point(lda.coherence_scores, maximize=True)
        perplexity_elbow = calculate_elbow_point(lda.perplexity_scores, maximize=False)
        
        # ìµœê³  ì„±ëŠ¥ ê³„ì‚°
        best_coherence_topic = max(lda.coherence_scores.keys(), key=lambda k: lda.coherence_scores[k])
        best_perplexity_topic = min(lda.perplexity_scores.keys(), key=lambda k: lda.perplexity_scores[k])
        
        # ì¶”ì²œ ë©”ì‹œì§€ - íŒŒë€ìƒ‰ ê³„ì—´ë¡œ í†µì¼
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown(f"""
            <div style="
                background-color: #E3F2FD;
                padding: 1.5rem;
                border-radius: 8px;
            ">
                <h4 style="color: #1976D2; margin: 0 0 1rem 0; font-size: 1.1rem;">ğŸ”· íš¨ìœ¨ì„± ê· í˜•ì </h4>
                <div style="color: #1565C0; font-size: 0.95rem; line-height: 1.6;">
                    <strong>Coherence:</strong> {coherence_elbow}ê°œ í† í”½<br>
                    <strong>Perplexity:</strong> {perplexity_elbow}ê°œ í† í”½
                </div>
                <p style="color: #1976D2; font-size: 0.85rem; margin-top: 0.8rem; margin-bottom: 0;">
                    ğŸ’¡ ì„±ëŠ¥ ëŒ€ë¹„ íš¨ìœ¨ì„±ì´ ê°€ì¥ ì¢‹ì€ ì§€ì 
                </p>
            </div>
            """, unsafe_allow_html=True)
        
        with col2:
            st.markdown(f"""
            <div style="
                background-color: #E8F4F8;
                padding: 1.5rem;
                border-radius: 8px;
            ">
                <h4 style="color: #0D47A1; margin: 0 0 1rem 0; font-size: 1.1rem;">ğŸ”µ ìµœê³  ì„±ëŠ¥</h4>
                <div style="color: #1565C0; font-size: 0.95rem; line-height: 1.6;">
                    <strong>Coherence:</strong> {best_coherence_topic}ê°œ ({lda.coherence_scores[best_coherence_topic]:.4f})<br>
                    <strong>Perplexity:</strong> {best_perplexity_topic}ê°œ ({lda.perplexity_scores[best_perplexity_topic]:.2f})
                </div>
                <p style="color: #1976D2; font-size: 0.85rem; margin-top: 0.8rem; margin-bottom: 0;">
                    ğŸ’¡ ê° ì§€í‘œì—ì„œ ìµœê³  ì„±ëŠ¥ì„ ë³´ì´ëŠ” ê°’
                </p>
            </div>
            """, unsafe_allow_html=True)
        
        st.markdown("""
        <div style="
            background-color: #FAFAFA;
            padding: 0.8rem 1.2rem;
            border-radius: 8px;
            margin-top: 1rem;
        ">
            <p style="color: #546E7A; font-size: 0.9rem; margin: 0;">
                ğŸ“Œ <strong>ì„ íƒ ê°€ì´ë“œ:</strong> í•´ì„ ìš©ì´ì„±ê³¼ ì†ë„ë¥¼ ì›í•˜ë©´ íš¨ìœ¨ì„± ê· í˜•ì (ğŸ”·ë°ì€ íŒŒë‘), ìµœê³  ì •í™•ë„ë¥¼ ì›í•˜ë©´ ìµœê³  ì„±ëŠ¥(ğŸ”µì§„í•œ íŒŒë‘) ì„ íƒ
            </p>
        </div>
        """, unsafe_allow_html=True)
        
        fig_metrics = create_metrics_comparison_chart(lda.coherence_scores, lda.perplexity_scores)
        st.plotly_chart(fig_metrics, use_container_width=True)
        
        
        st.markdown("---")
        
        # í† í”½ë³„ ìƒì„¸ ê²°ê³¼
        st.markdown("**í† í”½ë³„ ìƒì„¸ ê²°ê³¼**")
        
        selected_n_topics = st.selectbox(
            "í† í”½ ê°œìˆ˜ ì„ íƒ",
            options=sorted(lda.models.keys()),
            index=len(lda.models.keys())-1
        )
        
        model = lda.models[selected_n_topics]
        result_df = lda.get_result_df(selected_n_topics)
        
        # í†µê³„
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("ì „ì²´ ë¬¸ì„œ", f"{len(result_df):,}")
        with col2:
            st.metric("í† í”½ ìˆ˜", selected_n_topics)
        with col3:
            st.metric("Coherence", f"{lda.coherence_scores[selected_n_topics]:.4f}")
        with col4:
            st.metric("Perplexity", f"{lda.perplexity_scores[selected_n_topics]:.2f}")
        
        # í† í”½ ë¶„í¬
        fig_dist = create_topic_distribution_chart(result_df)
        st.plotly_chart(fig_dist, use_container_width=True)
        
        # í† í”½ë³„ í‚¤ì›Œë“œ
        st.markdown("**í† í”½ë³„ ì£¼ìš” í‚¤ì›Œë“œ**")
        keywords_df = create_topic_keywords_table(model, selected_n_topics)
        st.dataframe(keywords_df, use_container_width=True)
        
        st.markdown("---")
        
        # ============================================================================
        # í† í”½ ì„ íƒ ë° í•„í„°ë§
        # ============================================================================
        st.markdown('<div class="sub-header">ğŸ¯ í† í”½ ì„ íƒ ë° í•„í„°ë§</div>', unsafe_allow_html=True)
        
        st.write("**ë¶„ì„í•  í† í”½ì„ ì„ íƒí•˜ì„¸ìš”** (ê°ì„±ë¶„ì„/íšŒê·€ë¶„ì„ ë“± í›„ì† ë¶„ì„ìš©)")
        
        # í† í”½ ID ë¦¬ìŠ¤íŠ¸ ìƒì„±
        unique_topics = list(range(selected_n_topics))
        
        # í† í”½ë³„ ì •ë³´ë¥¼ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë§Œë“¤ê¸°
        topic_info = []
        for topic_id in unique_topics:
            count = (result_df['lda_topic'] == topic_id).sum()
            words = model.show_topic(topic_id, topn=5)
            keywords = ', '.join([word for word, prob in words])
            topic_info.append({
                'Topic ID': f"Topic {topic_id}",
                'ë¬¸ì„œ ìˆ˜': count,
                'ì£¼ìš” í‚¤ì›Œë“œ': keywords
            })
        
        topic_info_df = pd.DataFrame(topic_info)
        
        # í† í”½ ì •ë³´ í‘œì‹œ
        st.dataframe(topic_info_df, use_container_width=True, height=300)
        
        # í† í”½ ì„ íƒ UI
        col1, col2 = st.columns([3, 1])
        
        # session_state ì´ˆê¸°í™” (ë²„íŠ¼ ì•ì—)
        if 'selected_topics_list' not in st.session_state:
            st.session_state['selected_topics_list'] = unique_topics[:min(3, len(unique_topics))]
        
        with col2:
            if st.button("ğŸ”„ ì „ì²´ ì„ íƒ", key="select_all", use_container_width=True):
                st.session_state['selected_topics_list'] = unique_topics
            
            if st.button("âŒ ì „ì²´ í•´ì œ", key="clear_all", use_container_width=True):
                st.session_state['selected_topics_list'] = []
        
        with col1:
            selected_topics = st.multiselect(
                "ë¶„ì„í•  í† í”½ ì„ íƒ",
                options=unique_topics,
                default=st.session_state['selected_topics_list'],
                help="ì—¬ëŸ¬ ê°œ ì„ íƒ ê°€ëŠ¥í•©ë‹ˆë‹¤. ì„ íƒí•œ í† í”½ë§Œ í•„í„°ë§í•˜ì—¬ ì €ì¥ë©ë‹ˆë‹¤.",
                format_func=lambda x: f"Topic {x}"
            )
        
        # multiselect ê°’ ë³€ê²½ ì‹œ ì¦‰ì‹œ session_state ì—…ë°ì´íŠ¸
        if selected_topics != st.session_state['selected_topics_list']:
            st.session_state['selected_topics_list'] = selected_topics
        
        # ì„ íƒ ê²°ê³¼ í‘œì‹œ
        if selected_topics:
            filtered_df = result_df[result_df['lda_topic'].isin(selected_topics)].copy()
            
            st.markdown(f"""
            <div style="background-color: #F0F2F6; padding: 1rem; border-radius: 0.5rem; margin-bottom: 1rem;">
                âœ… <strong>{len(selected_topics)}ê°œ í† í”½ ì„ íƒë¨</strong> (ì´ {len(filtered_df):,}ê°œ ë¬¸ì„œ)
            </div>
            """, unsafe_allow_html=True)
            
            # ì„ íƒí•œ í† í”½ ìš”ì•½
            with st.expander("ğŸ“Š ì„ íƒí•œ í† í”½ ìš”ì•½"):
                for topic_id in selected_topics:
                    count = (filtered_df['lda_topic'] == topic_id).sum()
                    pct = count / len(filtered_df) * 100
                    words = model.show_topic(topic_id, topn=5)
                    keywords = ', '.join([f"{word}({prob:.3f})" for word, prob in words])
                    st.write(f"**Topic {topic_id}** ({count:,}ê°œ, {pct:.1f}%): {keywords}")
            
            # ì„¸ì…˜ì— ì €ì¥ (ë‹¤ë¥¸ ë¶„ì„ì—ì„œ ì‚¬ìš© ê°€ëŠ¥)
            st.session_state['filtered_df'] = filtered_df
            st.session_state['selected_topics'] = selected_topics
            
        else:
            st.warning("âš ï¸ ìµœì†Œ 1ê°œ ì´ìƒì˜ í† í”½ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
            filtered_df = result_df
        
        # ìƒì„¸ í† í”½ ì •ë³´
        with st.expander("ğŸ” í† í”½ë³„ ìƒì„¸ ì •ë³´"):
            for topic_id in unique_topics:
                count = (result_df['lda_topic'] == topic_id).sum()
                words = model.show_topic(topic_id, topn=10)
                keywords = ', '.join([f"{word}({prob:.3f})" for word, prob in words])
                
                # ì„ íƒëœ í† í”½ ê°•ì¡°
                if topic_id in selected_topics:
                    st.markdown(f"**âœ… Topic {topic_id}** ({count:,}ê°œ ë¬¸ì„œ) - **ì„ íƒë¨**")
                else:
                    st.markdown(f"**Topic {topic_id}** ({count:,}ê°œ ë¬¸ì„œ)")
                st.text(keywords)
                st.markdown("---")
        
        # ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°
        with st.expander("ğŸ“„ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° (ì²˜ìŒ 100ê°œ)"):
            display_cols = ['sentence', 'lda_topic']
            if 'company' in filtered_df.columns:
                display_cols.insert(1, 'company')
            if 'label' in filtered_df.columns:
                display_cols.insert(2, 'label')
            
            display_cols = [col for col in display_cols if col in filtered_df.columns]
            st.dataframe(filtered_df[display_cols].head(100), use_container_width=True)
        
        st.markdown("---")
        
                # =====================================================================
        # 5. ë‹¤ìš´ë¡œë“œ
        # =====================================================================
        st.markdown('<div class="sub-header">ğŸ’¾ 4. ê²°ê³¼ ë‹¤ìš´ë¡œë“œ</div>', unsafe_allow_html=True)

        st.info(f"ğŸ’¡ **ì„ íƒí•œ í† í”½ ({len(selected_topics)}ê°œ)ì˜ ë°ì´í„°ë§Œ ì €ì¥ë©ë‹ˆë‹¤** ({len(filtered_df):,}ê°œ ë¬¸ì„œ)")

        col1, col2, col3 = st.columns(3)

        # -----------------------------
        # 5-1. CSV ë‹¤ìš´ë¡œë“œ
        # -----------------------------
        with col1:
            st.write("**ğŸ“¥ CSV ë‹¤ìš´ë¡œë“œ**")

            csv_utf8sig = filtered_df.to_csv(index=False, encoding="utf-8-sig")
            file_name_csv = f"lda_{selected_n_topics}_topics_selected_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"

            st.download_button(
                label="CSV ë‹¤ìš´ë¡œë“œ (UTF-8-SIG, Excelìš©)",
                data=csv_utf8sig,
                file_name=file_name_csv,
                mime="text/csv",
                use_container_width=True,
                key="lda_download_csv",
            )

            st.caption(f"ğŸ’¡ ì„ íƒí•œ í† í”½: {len(selected_topics)}ê°œ / ë¬¸ì„œ: {len(filtered_df):,}ê°œ")

        # -----------------------------
        # 5-2. Excel ë‹¤ìš´ë¡œë“œ
        # -----------------------------
        with col2:
            st.write("**ğŸ“¥ Excel ë‹¤ìš´ë¡œë“œ**")

            buffer = BytesIO()
            try:
                with pd.ExcelWriter(buffer, engine="openpyxl") as writer:
                    # ì‹œíŠ¸ 1: ì„ íƒí•œ í† í”½ì˜ ë¬¸ì„œ
                    filtered_df.to_excel(writer, index=False, sheet_name="ì„ íƒí•œí† í”½")
                    # ì‹œíŠ¸ 2: ì „ì²´ í† í”½ í‚¤ì›Œë“œ
                    keywords_df.to_excel(writer, index=False, sheet_name="ì „ì²´í† í”½í‚¤ì›Œë“œ")
                    # ì‹œíŠ¸ 3: ì„ íƒí•œ í† í”½ ì •ë³´ë§Œ
                    selected_info_df = topic_info_df[
                        topic_info_df["Topic ID"].isin([f"Topic {x}" for x in selected_topics])
                    ]
                    selected_info_df.to_excel(writer, index=False, sheet_name="ì„ íƒí•œí† í”½ì •ë³´")

                excel_data = buffer.getvalue()
                file_name_xlsx = f"lda_{selected_n_topics}_topics_selected_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"

                st.download_button(
                    label="Excel ë‹¤ìš´ë¡œë“œ",
                    data=excel_data,
                    file_name=file_name_xlsx,
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    use_container_width=True,
                    key="lda_download_excel",
                )

            except ImportError:
                st.warning("âš ï¸ openpyxlì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•„ Excel ë‹¤ìš´ë¡œë“œë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                st.info("`pip install openpyxl` í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")

            st.caption("ğŸ’¡ 3ê°œ ì‹œíŠ¸ í¬í•¨ (ì„ íƒí•œí† í”½, ì „ì²´í† í”½í‚¤ì›Œë“œ, ì„ íƒí•œí† í”½ì •ë³´)")

        # -----------------------------
        # 5-3. ë©”íƒ€ë°ì´í„°(JSON) ë‹¤ìš´ë¡œë“œ
        # -----------------------------
        with col3:
            st.write("**ğŸ“¥ ë©”íƒ€ë°ì´í„°(JSON) ë‹¤ìš´ë¡œë“œ**")

            metadata = {
                "n_topics": selected_n_topics,
                "total_documents": len(result_df),
                "selected_topics": selected_topics,
                "filtered_documents": len(filtered_df),
                "coherence_score": float(lda.coherence_scores[selected_n_topics]),
                "perplexity_score": float(lda.perplexity_scores[selected_n_topics]),
                "parameters": {
                    "passes": passes,
                    "iterations": iterations,
                    "alpha": str(alpha),  # auto / symmetric ë“± ë¬¸ìì—´ì¼ ìˆ˜ ìˆì–´ì„œ str
                    "eta": str(eta),
                    "no_below": no_below,
                    "no_above": no_above,
                    "keep_n": keep_n,
                },
                "timestamp": datetime.now().isoformat(),
            }

            json_str = json.dumps(metadata, ensure_ascii=False, indent=2)
            file_name_json = f"lda_{selected_n_topics}_metadata_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"

            st.download_button(
                label="ë©”íƒ€ë°ì´í„° JSON ë‹¤ìš´ë¡œë“œ",
                data=json_str.encode("utf-8"),
                file_name=file_name_json,
                mime="application/json",
                use_container_width=True,
                key="lda_download_json",
            )

            st.caption("ğŸ’¡ í•™ìŠµ íŒŒë¼ë¯¸í„° ë° ì„ íƒ í† í”½ ì •ë³´ í¬í•¨")


if __name__ == "__main__":
    main()